{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, \\\n",
    "  Concatenate\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/rmedal/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074/sklearn-0.0-py2.py3-none-any.whl\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.22.2-cp36-cp36m-manylinux1_x86_64.whl (7.1 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/rmedal/.virtualenvs/recommender-movies/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/rmedal/.virtualenvs/recommender-movies/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Installing collected packages: joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22.2 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "#import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        2     3.5  1112486027\n",
       "1       1       29     3.5  1112484676\n",
       "2       1       32     3.5  1112484819\n",
       "3       1       47     3.5  1112484727\n",
       "4       1       50     3.5  1112484580"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train/local-test/test_dir/input/data/ratings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    1\n",
       "Name: userId, dtype: category\n",
       "Categories (138493, int64): [1, 2, 3, 4, ..., 138490, 138491, 138492, 138493]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.userId = pd.Categorical(df.userId)\n",
    "df['new_user_id'] = df.userId.cat.codes\n",
    "df.userId[12:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    318\n",
       "Name: movieId, dtype: category\n",
       "Categories (26744, int64): [1, 2, 3, 4, ..., 131256, 131258, 131260, 131262]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.movieId = pd.Categorical(df.movieId)\n",
    "df['new_movie_id'] = df.movieId.cat.codes\n",
    "df.movieId[12:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    4.0\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get user IDs, movie IDs, and ratings as separate arrays\n",
    "user_ids = df['new_user_id'].values\n",
    "movie_ids = df['new_movie_id'].values\n",
    "ratings = df['rating'].values\n",
    "df.rating[12:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      0      0 ... 138492 138492 138492]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(user_ids)\n",
    "print(user_ids[12:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1    28    31 ... 13875 13993 14277]\n",
      "[315]\n"
     ]
    }
   ],
   "source": [
    "print(movie_ids)\n",
    "print(movie_ids[12:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.]\n"
     ]
    }
   ],
   "source": [
    "print(ratings[12:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get number of users and number of movies\n",
    "N = len(set(user_ids))\n",
    "M = len(set(movie_ids))\n",
    "\n",
    "# Set embedding dimension\n",
    "K = 10\n",
    "\n",
    "# N = 1\n",
    "# M = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a neural network\n",
    "\n",
    "# User input\n",
    "u = Input(shape=(1,))\n",
    "\n",
    "# Movie input\n",
    "m = Input(shape=(1,))\n",
    "\n",
    "# User embedding\n",
    "u_emb = Embedding(N, K)(u) # output is (num_samples, 1, K)\n",
    "\n",
    "# Movie embedding\n",
    "m_emb = Embedding(M, K)(m) # output is (num_samples, 1, K)\n",
    "\n",
    "# Flatten both embeddings\n",
    "u_emb = Flatten()(u_emb) # now it's (num_samples, K)\n",
    "m_emb = Flatten()(m_emb) # now it's (num_samples, K)\n",
    "\n",
    "# Concatenate user-movie embeddings into a feature vector\n",
    "x = Concatenate()([u_emb, m_emb]) # now it's (num_samples, 2K)\n",
    "\n",
    "# Now that we have a feature vector, it's just a regular ANN\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# x = Dense(400, activation='relu')(x)\n",
    "# x = Dense(400, activation='relu')(x)\n",
    "x = Dense(1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concatenate/Identity:0\", shape=(None, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model and compile\n",
    "model = Model(inputs=[u, m], outputs=x)\n",
    "model.compile(\n",
    "  loss='mse',\n",
    "  optimizer=SGD(lr=0.08, momentum=0.9),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "user_ids, movie_ids, ratings = shuffle(user_ids, movie_ids, ratings)\n",
    "Ntrain = int(0.8 * len(ratings))\n",
    "train_user = user_ids[:Ntrain]\n",
    "train_movie = movie_ids[:Ntrain]\n",
    "train_ratings = ratings[:Ntrain]\n",
    "\n",
    "test_user = user_ids[Ntrain:]\n",
    "test_movie = movie_ids[Ntrain:]\n",
    "test_ratings = ratings[Ntrain:]\n",
    "\n",
    "# center the ratings\n",
    "avg_rating = train_ratings.mean()\n",
    "train_ratings = train_ratings - avg_rating\n",
    "test_ratings = test_ratings - avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000210 samples, validate on 4000053 samples\n",
      "Epoch 1/25\n",
      "16000210/16000210 - 115s - loss: 0.7763 - val_loss: 0.7232\n",
      "Epoch 2/25\n",
      "16000210/16000210 - 113s - loss: 0.7014 - val_loss: 0.7038\n",
      "Epoch 3/25\n",
      "16000210/16000210 - 110s - loss: 0.6797 - val_loss: 0.6862\n",
      "Epoch 4/25\n",
      "16000210/16000210 - 111s - loss: 0.6640 - val_loss: 0.6759\n",
      "Epoch 5/25\n",
      "16000210/16000210 - 116s - loss: 0.6534 - val_loss: 0.6719\n",
      "Epoch 6/25\n",
      "16000210/16000210 - 111s - loss: 0.6419 - val_loss: 0.6607\n",
      "Epoch 7/25\n",
      "16000210/16000210 - 107s - loss: 0.6253 - val_loss: 0.6492\n",
      "Epoch 8/25\n",
      "16000210/16000210 - 107s - loss: 0.6118 - val_loss: 0.6439\n",
      "Epoch 9/25\n",
      "16000210/16000210 - 107s - loss: 0.6021 - val_loss: 0.6426\n",
      "Epoch 10/25\n",
      "16000210/16000210 - 106s - loss: 0.5935 - val_loss: 0.6381\n",
      "Epoch 11/25\n",
      "16000210/16000210 - 106s - loss: 0.5857 - val_loss: 0.6411\n",
      "Epoch 12/25\n",
      "16000210/16000210 - 106s - loss: 0.5785 - val_loss: 0.6353\n",
      "Epoch 13/25\n",
      "16000210/16000210 - 106s - loss: 0.5721 - val_loss: 0.6323\n",
      "Epoch 14/25\n",
      "16000210/16000210 - 106s - loss: 0.5661 - val_loss: 0.6322\n",
      "Epoch 15/25\n",
      "16000210/16000210 - 106s - loss: 0.5610 - val_loss: 0.6327\n",
      "Epoch 16/25\n",
      "16000210/16000210 - 106s - loss: 0.5564 - val_loss: 0.6303\n",
      "Epoch 17/25\n",
      "16000210/16000210 - 106s - loss: 0.5525 - val_loss: 0.6292\n",
      "Epoch 18/25\n",
      "16000210/16000210 - 107s - loss: 0.5490 - val_loss: 0.6275\n",
      "Epoch 19/25\n",
      "16000210/16000210 - 107s - loss: 0.5459 - val_loss: 0.6289\n",
      "Epoch 20/25\n",
      "16000210/16000210 - 107s - loss: 0.5431 - val_loss: 0.6291\n",
      "Epoch 21/25\n",
      "16000210/16000210 - 106s - loss: 0.5406 - val_loss: 0.6321\n",
      "Epoch 22/25\n",
      "16000210/16000210 - 106s - loss: 0.5383 - val_loss: 0.6265\n",
      "Epoch 23/25\n",
      "16000210/16000210 - 106s - loss: 0.5363 - val_loss: 0.6314\n",
      "Epoch 24/25\n",
      "16000210/16000210 - 107s - loss: 0.5343 - val_loss: 0.6275\n",
      "Epoch 25/25\n",
      "16000210/16000210 - 106s - loss: 0.5326 - val_loss: 0.6271\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "  x=[train_user, train_movie],\n",
    "  y=train_ratings,\n",
    "  epochs=25,\n",
    "  batch_size=1024,\n",
    "  verbose=2, # goes a little faster when you don't print the progress bar\n",
    "  validation_data=([test_user, test_movie], test_ratings),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = /tmp/1\n",
      "\n",
      "WARNING:tensorflow:From /home/rmedal/.virtualenvs/recommender-movies/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /tmp/1/assets\n",
      "\n",
      "Saved model:\n",
      "total 124\n",
      "drwxr-xr-x 2 rmedal rmedal   4096 Mar  2 15:09 assets\n",
      "-rw-r--r-- 1 rmedal rmedal 117609 Mar  2 15:09 saved_model.pb\n",
      "drwxr-xr-x 2 rmedal rmedal   4096 Mar  2 15:09 variables\n"
     ]
    }
   ],
   "source": [
    "# Save the model to a temporary directory\n",
    "import tempfile\n",
    "\n",
    "MODEL_DIR = tempfile.gettempdir()\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "if os.path.isdir(export_path):\n",
    "  print('\\nAlready saved a model, cleaning up\\n')\n",
    "  !rm -r {export_path}\n",
    "\n",
    "tf.saved_model.save(model, export_path)\n",
    "\n",
    "print('\\nSaved model:')\n",
    "!ls -l {export_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_3'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: serving_default_input_3:0\n",
      "    inputs['input_4'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: serving_default_input_4:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense_1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {export_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[train_user[1:2], train_movie[1:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([99878], dtype=int32), array([3593], dtype=int16)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"signature_name\": \"serving_default\", \"instances\": [[99878], [3593]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": x_test}, cls=NumpyArrayEncoder)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
